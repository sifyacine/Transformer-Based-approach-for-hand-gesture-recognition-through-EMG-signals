{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "     -------------------------------------- 390.0/390.0 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "     -------------------------------------- 434.5/434.5 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "     ---------------------------------------- 15.9/15.9 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\ycn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (63.2.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     ---------------------------------------- 26.4/26.4 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "     -------------------------------------- 126.6/126.6 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ycn\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\ycn\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.7/133.7 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ycn\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.9/71.9 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.14.0-cp310-cp310-win_amd64.whl (290 kB)\n",
      "     -------------------------------------- 290.9/290.9 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     -------------------------------------- 242.4/242.4 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "     -------------------------------------- 102.8/102.8 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.4/70.4 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "     -------------------------------------- 166.4/166.4 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "     -------------------------------------- 128.4/128.4 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.3/106.3 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "     -------------------------------------- 224.5/224.5 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ycn\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.1.24 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.12.1 idna-3.10 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 protobuf-5.29.3 requests-2.32.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2966,
     "status": "ok",
     "timestamp": 1632432894173,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "gq_kAOZp0A3s"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1632432894176,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "q0y39MP5J12v"
   },
   "outputs": [],
   "source": [
    "def get_signals_info(emg, restimulus, debut , fin):\n",
    "    emg_signals = emg[debut:fin]\n",
    "    emg_labels_ = restimulus[debut:fin]\n",
    "    emg_labels = list(map(lambda x: x[0], emg_labels_))\n",
    "    return emg_signals, emg_labels\n",
    "    \n",
    "def get_index_list(labels, index_mouve):\n",
    "  index_list = ([np.where(labels == index_mouve) ])\n",
    "  return np.squeeze(np.concatenate(index_list, axis=1))\n",
    "  \n",
    "##########################################################################################################################\n",
    "def cpt_mouvements(db_labels):\n",
    "  cpt = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "  for i in db_labels:\n",
    "    cpt[i] += 1\n",
    "  return cpt\n",
    "\n",
    "def cpt_mouvements_v2(db_labels):\n",
    "  cpt = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "  print(db_labels.shape)\n",
    "\n",
    "  for i in range(db_labels.shape[0]):\n",
    "    for j in range(db_labels.shape[1]):\n",
    "      if db_labels[i][j] == 1:\n",
    "          cpt[j] += 1\n",
    "  return cpt\n",
    "\n",
    "def affich_mouvements(db_labels):\n",
    "  total = 0  \n",
    "  cpt = cpt_mouvements_v2(db_labels)\n",
    "\n",
    "  for j in range(len(cpt)):\n",
    "    if cpt[j] > 0:\n",
    "      total += cpt[j]\n",
    "      print(\"> mouvement \"+str(j)+ \" : \" + str(cpt[j]))\n",
    "  print(\"> Le nombre total d'echantillons : \" + str(total) )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1632432894668,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "GrzBAEA364yA"
   },
   "outputs": [],
   "source": [
    "def creat_dataset(emg, restimulus, debut, fin, window = 300, window_inc = 300, ratio = (2/3)): #\n",
    "  ### Signals ### \n",
    "  data_set = []\n",
    "  ### labels ### \n",
    "  cpt_mouvements= 0\n",
    "  select_val = int((window * ratio))  ##########################################\n",
    "  labels_list = []\n",
    "  current_mouv = 0\n",
    "              ########################### \n",
    "  for pose in range(len(debut)) : \n",
    "\n",
    "    train_signals, train_labels = get_signals_info(emg, restimulus, debut[pose], fin[pose])\n",
    "      \n",
    "    for i in range(int((fin[pose]-debut[pose])/window_inc)):\n",
    "      startL = i * window_inc\n",
    "      endL = startL + window\n",
    "      if endL > (fin[pose]-debut[pose]):\n",
    "        break;\n",
    "      else:\n",
    "\n",
    "        ### labels ###\n",
    "        for j in range(startL, endL):\n",
    "          if train_labels[j] > 0:\n",
    "            if train_labels[j] > current_mouv:\n",
    "                current_mouv = train_labels[j]\n",
    "                cpt_mouvements = 1\n",
    "            elif int(train_labels[j]) == int(current_mouv):\n",
    "                cpt_mouvements += 1\n",
    "        if cpt_mouvements > select_val:\n",
    "                if current_mouv > 9:\n",
    "                   labels_list.append(current_mouv-2)\n",
    "                else:\n",
    "                  labels_list.append(current_mouv)\n",
    "\n",
    "                ### Signals ###\n",
    "                data_set.append(train_signals[startL:endL])           \n",
    "        elif cpt_mouvements == 0:\n",
    "                labels_list.append(0)\n",
    "                ### Signals ###\n",
    "                data_set.append(train_signals[startL:endL])\n",
    "                \n",
    "        cpt_mouvements = 0\n",
    "        current_mouv = 0\n",
    "\n",
    "  return data_set, labels_list\n",
    "\n",
    "def remouve_mouves(train_data,train_labels,test_data,test_labels):\n",
    "\n",
    "    cpt_train = cpt_mouvements(train_labels)\n",
    "    cpt_test = cpt_mouvements(test_labels)\n",
    "\n",
    "\n",
    "    train_mean = int(stat.mean(cpt_train[1:16]))\n",
    "    test_mean = int(stat.mean(cpt_test[1:16]))\n",
    "\n",
    "    for i in range(len(cpt_train)):\n",
    "\n",
    "      to_remove_train = cpt_train[i] - int(train_mean)\n",
    "      to_remove_test = cpt_test[i] - int(test_mean)\n",
    "\n",
    "      if to_remove_train > 0:  \n",
    "        zeros_list = get_index_list(train_labels, i)\n",
    "        zeros_toremove = random.sample(list(zeros_list), to_remove_train)\n",
    "\n",
    "        train_labels = np.delete(train_labels, zeros_toremove, axis=0)\n",
    "        train_data = np.delete(train_data, zeros_toremove, axis=0)\n",
    "\n",
    "      if to_remove_test > 0:\n",
    "        zeros_list = get_index_list(test_labels, i)\n",
    "        zeros_toremove = random.sample(list(zeros_list), to_remove_test)\n",
    "\n",
    "        test_labels = np.delete(test_labels, zeros_toremove, axis=0)\n",
    "        test_data = np.delete(test_data, zeros_toremove, axis=0)\n",
    "    \n",
    "    return train_data,train_labels,test_data,test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1632432894668,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "qnDUi7XzjrNi"
   },
   "outputs": [],
   "source": [
    "def dataset_normalize(train_data, test_data):\n",
    "\n",
    "  train_data = np.array(train_data)\n",
    "  test_data = np.array(test_data)\n",
    "\n",
    "  train_x = train_data.shape[0]\n",
    "  train_y = train_data.shape[1]\n",
    "  train_z = train_data.shape[2]\n",
    "\n",
    "  test_x = test_data.shape[0]\n",
    "  test_y = test_data.shape[1]\n",
    "  test_z = test_data.shape[2]\n",
    "\n",
    "  train_data = train_data.reshape(train_x*train_y, train_z)\n",
    "  test_data = test_data.reshape(test_x*test_y, test_z)\n",
    "\n",
    "  scaler = StandardScaler(with_mean=True, with_std=True).fit(train_data)\n",
    "  \n",
    "  train_N = scaler.transform(train_data)\n",
    "  test_N = scaler.transform(test_data)\n",
    "\n",
    "  train_N = train_N.reshape(train_x, train_y, train_z)\n",
    "  test_N = test_N.reshape(test_x, test_y, test_z)\n",
    "  return train_N, test_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1632432894174,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "f5RFoJHhPese"
   },
   "outputs": [],
   "source": [
    "#Determiner le debut et la fin de chaque repetition pour chaque mouvement \n",
    "def get_labels_interv(rerepitition):\n",
    "  rerepitition = np.squeeze(rerepitition)\n",
    "  global_labels = []\n",
    "  local_labels = [0]\n",
    "  mouvement = 1\n",
    "  cpt = 0\n",
    "  for i in range(len(rerepitition)):\n",
    "    if rerepitition[i] == 0:\n",
    "      local_labels.append(i)\n",
    "      global_labels.append(local_labels)\n",
    "      cpt = 0\n",
    "      break\n",
    "    elif rerepitition[i] != mouvement:\n",
    "      cpt += 1\n",
    "      local_labels.append(i)\n",
    "      mouvement = rerepitition[i]\n",
    "      if mouvement == 1 and cpt == 6:\n",
    "        global_labels.append(local_labels)\n",
    "        local_labels = [i]                            \n",
    "        cpt = 0\n",
    "  return global_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1632432894174,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "VyJXajN4UZGk"
   },
   "outputs": [],
   "source": [
    "#L'intervalle d'etude\n",
    "def start_end_list(rerepetition= [], window= 300, rep_train = [1,2,4,6], rep_test = [3,5]):\n",
    "  global_labels = get_labels_interv(rerepetition)\n",
    "  train_debut = []\n",
    "  train_fin = []\n",
    "  test_debut = []\n",
    "  test_fin = []\n",
    "\n",
    "  for i in global_labels[:9]: \n",
    "    for j in rep_train:\n",
    "      train_debut.append(i[j-1])\n",
    "      fin = int((i[j]-i[j-1])/window)*window + i[j-1]\n",
    "      train_fin.append(fin)\n",
    "    for k in rep_test:\n",
    "      test_debut.append(i[k-1])\n",
    "      fin = int((i[k]-i[k-1])/window)*window + i[k-1]\n",
    "      test_fin.append(fin)\n",
    "    \n",
    "  for i in global_labels[11:]: \n",
    "    for j in rep_train:\n",
    "      train_debut.append(i[j-1])\n",
    "      fin = int((i[j]-i[j-1])/window)*window + i[j-1]\n",
    "      train_fin.append(fin)\n",
    "    for k in rep_test:\n",
    "      test_debut.append(i[k-1])\n",
    "      fin = int((i[k]-i[k-1])/window)*window + i[k-1]\n",
    "      test_fin.append(fin)\n",
    "\n",
    "  return train_debut,train_fin,test_debut,test_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1632432894669,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "iGNPYKODBBns"
   },
   "outputs": [],
   "source": [
    "def creation(filename, window = 300, window_inc = 300, ratio = (2/3)):\n",
    "  train_data = []\n",
    "  train_labels = []\n",
    "  test_data = []\n",
    "  test_labels = []\n",
    "  \n",
    "  for sujet in filename:\n",
    "    data = loadmat(sujet)\n",
    "    emg = data['emg']\n",
    "    restimulus = data['restimulus']\n",
    "    rerepetition = data['rerepetition']\n",
    "\n",
    "    train_debut,train_fin,test_debut,test_fin = start_end_list(rerepetition, window= window)\n",
    "\n",
    "    trainX, trainY = creat_dataset(emg = emg, restimulus = restimulus, debut = train_debut, fin = train_fin, window = window, window_inc = window_inc, ratio = ratio )\n",
    "    testX, testY = creat_dataset(emg = emg, restimulus = restimulus, debut = test_debut, fin = test_fin, window = window, window_inc = window_inc, ratio = ratio)\n",
    "\n",
    "    train_data.extend(trainX)\n",
    "    train_labels.extend(trainY)\n",
    "    test_data.extend(testX)\n",
    "    test_labels.extend(testY)\n",
    "\n",
    "  ### Signals ### \n",
    "  train_data = np.array(train_data)\n",
    "  test_data = np.array(test_data)\n",
    "  ### labels ###      \n",
    "  train_labels = np.array(train_labels)\n",
    "  test_labels = np.array(test_labels)\n",
    "\n",
    "  train_data,train_labels,test_data,test_labels = remouve_mouves(train_data,train_labels,test_data,test_labels)\n",
    "\n",
    "\n",
    "  train_labels = to_categorical(train_labels) \n",
    "  test_labels = to_categorical(test_labels)\n",
    "\n",
    "  return train_data,train_labels,test_data,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 15448,
     "status": "ok",
     "timestamp": 1632432910113,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "SzhbIxeDmvch"
   },
   "outputs": [],
   "source": [
    "############# Creation du Dataset ########\n",
    "Subjects = []\n",
    "for i in range(1, 12):  # Looping through DB3_s1 to DB3_s11\n",
    "    subject_folder = f\"DB3_s{i}\"  # Folder name (e.g., DB3_s1)\n",
    "    subject_file = f\"S{i}_E1_A1.mat\"  # File name (e.g., S1_E1_A1.mat)\n",
    "    \n",
    "    input_path = fr\"G:\\former students work\\Code source\\DB3\\{subject_folder}\\{subject_file}\"\n",
    "    train_data, train_labels, test_data, test_labels = creation(filename=[input_path], window=300, window_inc=200)\n",
    "\n",
    "    output_path = fr\"G:\\former students work\\Code source\\DB3_new\\DB3_s{i}_E1_A1_150_100.mat\"\n",
    "    new_data = {'train_data': train_data, 'train_labels': train_labels, 'test_data': test_data, 'test_labels': test_labels}\n",
    "    savemat(output_path, new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1632432894669,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "nFFpFuWujvev"
   },
   "outputs": [],
   "source": [
    "def create_normalized_dataset(filename):\n",
    "\n",
    "    data = loadmat(r\"\"+ filename +\"\")\n",
    "    train_data = data['train_data']\n",
    "    test_data  = data['test_data']\n",
    "\n",
    "    train_N, test_N = dataset_normalize(train_data, test_data)\n",
    "    return train_N, data['train_labels'], test_N, data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1632432910842,
     "user": {
      "displayName": "EMG hand gesture Recognition system",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16267807696113233248"
     },
     "user_tz": -60
    },
    "id": "umCjIg61j8Ls"
   },
   "outputs": [],
   "source": [
    "############# Creation d'un dataset avec des données normalisées ########\n",
    "for i in range(1, 12):  # Adjusted to match DB3_s1 to DB3_s11\n",
    "    Subject = fr\"G:\\former students work\\Code source\\DB3_new\\DB3_s{i}_E1_A1_150_100.mat\"\n",
    "    train_N, train_labels, test_N, test_labels = create_normalized_dataset(Subject)\n",
    "\n",
    "    output_path = fr\"G:\\former students work\\Code source\\DB3_new\\DB3_s{i}_E1_A1_150_100_N.mat\"\n",
    "    new_data = {'train_data': train_N, 'train_labels': train_labels, 'test_data': test_N, 'test_labels': test_labels}\n",
    "    savemat(output_path, new_data)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "create_dataset_vf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
